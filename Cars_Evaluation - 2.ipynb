{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "      <th>make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>2017</td>\n",
       "      <td>12500</td>\n",
       "      <td>Manual</td>\n",
       "      <td>15735</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>150</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A6</td>\n",
       "      <td>2016</td>\n",
       "      <td>16500</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>36203</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>20</td>\n",
       "      <td>64.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1</td>\n",
       "      <td>2016</td>\n",
       "      <td>11000</td>\n",
       "      <td>Manual</td>\n",
       "      <td>29946</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>30</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4</td>\n",
       "      <td>2017</td>\n",
       "      <td>16800</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>25952</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>67.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3</td>\n",
       "      <td>2019</td>\n",
       "      <td>17300</td>\n",
       "      <td>Manual</td>\n",
       "      <td>1998</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>145</td>\n",
       "      <td>49.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85550</th>\n",
       "      <td>Eos</td>\n",
       "      <td>2012</td>\n",
       "      <td>5990</td>\n",
       "      <td>Manual</td>\n",
       "      <td>74000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>125</td>\n",
       "      <td>58.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Volkswagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85551</th>\n",
       "      <td>Fox</td>\n",
       "      <td>2008</td>\n",
       "      <td>1799</td>\n",
       "      <td>Manual</td>\n",
       "      <td>88102</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>145</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Volkswagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85552</th>\n",
       "      <td>Fox</td>\n",
       "      <td>2009</td>\n",
       "      <td>1590</td>\n",
       "      <td>Manual</td>\n",
       "      <td>70000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>200</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Volkswagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85553</th>\n",
       "      <td>Fox</td>\n",
       "      <td>2006</td>\n",
       "      <td>1250</td>\n",
       "      <td>Manual</td>\n",
       "      <td>82704</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>150</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Volkswagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85554</th>\n",
       "      <td>Fox</td>\n",
       "      <td>2007</td>\n",
       "      <td>2295</td>\n",
       "      <td>Manual</td>\n",
       "      <td>74000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>145</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Volkswagen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85555 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  year  price transmission  mileage fuelType  tax   mpg  \\\n",
       "0        A1  2017  12500       Manual    15735   Petrol  150  55.4   \n",
       "1        A6  2016  16500    Automatic    36203   Diesel   20  64.2   \n",
       "2        A1  2016  11000       Manual    29946   Petrol   30  55.4   \n",
       "3        A4  2017  16800    Automatic    25952   Diesel  145  67.3   \n",
       "4        A3  2019  17300       Manual     1998   Petrol  145  49.6   \n",
       "...     ...   ...    ...          ...      ...      ...  ...   ...   \n",
       "85550   Eos  2012   5990       Manual    74000   Diesel  125  58.9   \n",
       "85551   Fox  2008   1799       Manual    88102   Petrol  145  46.3   \n",
       "85552   Fox  2009   1590       Manual    70000   Petrol  200  42.0   \n",
       "85553   Fox  2006   1250       Manual    82704   Petrol  150  46.3   \n",
       "85554   Fox  2007   2295       Manual    74000   Petrol  145  46.3   \n",
       "\n",
       "       engineSize        make  \n",
       "0             1.4        Audi  \n",
       "1             2.0        Audi  \n",
       "2             1.4        Audi  \n",
       "3             2.0        Audi  \n",
       "4             1.0        Audi  \n",
       "...           ...         ...  \n",
       "85550         2.0  Volkswagen  \n",
       "85551         1.2  Volkswagen  \n",
       "85552         1.4  Volkswagen  \n",
       "85553         1.2  Volkswagen  \n",
       "85554         1.2  Volkswagen  \n",
       "\n",
       "[85555 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the data for all car makes\n",
    "path = r'C:\\Users\\adria\\Documents\\GitHub\\UsedCarsValuePredictionML\\Data' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "brands = [\"Audi\",\"BMW\",\"Ford\",\"Hyundi\",\"Mercedes Benz\",\"Skoda\",\"Toyota\",\"Volkswagen\"]\n",
    "\n",
    "for filename, brand in zip(all_files, brands):\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    df[\"make\"] = brand\n",
    "    li.append(df)\n",
    "    \n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.loc[df['year']<2021,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('frame.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 85554 entries, 0 to 85554\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   model         85554 non-null  object \n",
      " 1   year          85554 non-null  int64  \n",
      " 2   price         85554 non-null  int64  \n",
      " 3   transmission  85554 non-null  object \n",
      " 4   mileage       85554 non-null  int64  \n",
      " 5   fuelType      85554 non-null  object \n",
      " 6   tax           85554 non-null  int64  \n",
      " 7   mpg           85554 non-null  float64\n",
      " 8   engineSize    85554 non-null  float64\n",
      " 9   make          85554 non-null  object \n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-41760f7611f17b25",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "      <th>model_ 1 Series</th>\n",
       "      <th>model_ 2 Series</th>\n",
       "      <th>model_ 3 Series</th>\n",
       "      <th>model_ 4 Series</th>\n",
       "      <th>...</th>\n",
       "      <th>fuelType_Other</th>\n",
       "      <th>fuelType_Petrol</th>\n",
       "      <th>make_Audi</th>\n",
       "      <th>make_BMW</th>\n",
       "      <th>make_Ford</th>\n",
       "      <th>make_Hyundi</th>\n",
       "      <th>make_Mercedes Benz</th>\n",
       "      <th>make_Skoda</th>\n",
       "      <th>make_Toyota</th>\n",
       "      <th>make_Volkswagen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>12500</td>\n",
       "      <td>15735</td>\n",
       "      <td>150</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>16500</td>\n",
       "      <td>36203</td>\n",
       "      <td>20</td>\n",
       "      <td>64.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>11000</td>\n",
       "      <td>29946</td>\n",
       "      <td>30</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>16800</td>\n",
       "      <td>25952</td>\n",
       "      <td>145</td>\n",
       "      <td>67.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>17300</td>\n",
       "      <td>1998</td>\n",
       "      <td>145</td>\n",
       "      <td>49.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  price  mileage  tax   mpg  engineSize  model_ 1 Series  \\\n",
       "0  2017  12500    15735  150  55.4         1.4                0   \n",
       "1  2016  16500    36203   20  64.2         2.0                0   \n",
       "2  2016  11000    29946   30  55.4         1.4                0   \n",
       "3  2017  16800    25952  145  67.3         2.0                0   \n",
       "4  2019  17300     1998  145  49.6         1.0                0   \n",
       "\n",
       "   model_ 2 Series  model_ 3 Series  model_ 4 Series  ...  fuelType_Other  \\\n",
       "0                0                0                0  ...               0   \n",
       "1                0                0                0  ...               0   \n",
       "2                0                0                0  ...               0   \n",
       "3                0                0                0  ...               0   \n",
       "4                0                0                0  ...               0   \n",
       "\n",
       "   fuelType_Petrol  make_Audi  make_BMW  make_Ford  make_Hyundi  \\\n",
       "0                1          1         0          0            0   \n",
       "1                0          1         0          0            0   \n",
       "2                1          1         0          0            0   \n",
       "3                0          1         0          0            0   \n",
       "4                1          1         0          0            0   \n",
       "\n",
       "   make_Mercedes Benz  make_Skoda  make_Toyota  make_Volkswagen  \n",
       "0                   0           0            0                0  \n",
       "1                   0           0            0                0  \n",
       "2                   0           0            0                0  \n",
       "3                   0           0            0                0  \n",
       "4                   0           0            0                0  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Use Pandas get_dummies to convert categorical data\n",
    "frame_one_hot = pd.get_dummies(df, columns =['model', 'transmission', 'fuelType', 'make'])\n",
    "frame_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a61368ced39885a2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85554, 195) (85554, 1)\n"
     ]
    }
   ],
   "source": [
    "# # Assign X (data) and y (target)\n",
    "X = frame_one_hot.drop(['price'],axis=1)\n",
    "y = frame_one_hot[\"price\"].values.reshape(-1, 1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62193e4c8caef9c5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a885840c1f62d274",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Scale Data\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "y_scaler = MinMaxScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler and y_scaler models\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92      , 0.09169364, 0.05172414, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.94      , 0.03684679, 0.25      , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.01332671, 0.25      , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.92      , 0.1085137 , 0.05172414, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.00185001, 0.25      , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.01176337, 0.25      , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               19600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 24,701\n",
      "Trainable params: 24,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel = Sequential()\n",
    "NNmodel.add(Dense(100, input_dim=195, kernel_initializer='normal', activation='relu'))\n",
    "NNmodel.add(Dense(50, activation='relu'))\n",
    "NNmodel.add(Dense(1, activation='linear'))\n",
    "NNmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " 944/1027 [==========================>...] - ETA: 0s - loss: 8.1856e-04 - mse: 8.1856e-04 - mae: 0.0175WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1027/1027 [==============================] - 1s 794us/step - loss: 7.9783e-04 - mse: 7.9783e-04 - mae: 0.0172 - val_loss: 4.4443e-04 - val_mse: 4.4443e-04 - val_mae: 0.0133\n",
      "Epoch 2/150\n",
      "1027/1027 [==============================] - 1s 689us/step - loss: 4.2869e-04 - mse: 4.2869e-04 - mae: 0.0133 - val_loss: 4.1736e-04 - val_mse: 4.1736e-04 - val_mae: 0.0137\n",
      "Epoch 3/150\n",
      "1027/1027 [==============================] - 1s 680us/step - loss: 3.8711e-04 - mse: 3.8711e-04 - mae: 0.0126 - val_loss: 3.5076e-04 - val_mse: 3.5076e-04 - val_mae: 0.0119\n",
      "Epoch 4/150\n",
      "1027/1027 [==============================] - 1s 689us/step - loss: 3.5229e-04 - mse: 3.5229e-04 - mae: 0.0120 - val_loss: 3.5206e-04 - val_mse: 3.5206e-04 - val_mae: 0.0124\n",
      "Epoch 5/150\n",
      "1027/1027 [==============================] - 1s 687us/step - loss: 3.3146e-04 - mse: 3.3146e-04 - mae: 0.0117 - val_loss: 2.9941e-04 - val_mse: 2.9941e-04 - val_mae: 0.0113\n",
      "Epoch 6/150\n",
      "1027/1027 [==============================] - 1s 703us/step - loss: 3.1583e-04 - mse: 3.1583e-04 - mae: 0.0114 - val_loss: 2.9960e-04 - val_mse: 2.9960e-04 - val_mae: 0.0113\n",
      "Epoch 7/150\n",
      "1027/1027 [==============================] - 1s 703us/step - loss: 3.0280e-04 - mse: 3.0280e-04 - mae: 0.0111 - val_loss: 2.8520e-04 - val_mse: 2.8520e-04 - val_mae: 0.0114\n",
      "Epoch 8/150\n",
      "1027/1027 [==============================] - 1s 687us/step - loss: 2.8587e-04 - mse: 2.8587e-04 - mae: 0.0108 - val_loss: 3.1050e-04 - val_mse: 3.1050e-04 - val_mae: 0.0120\n",
      "Epoch 9/150\n",
      "1027/1027 [==============================] - 1s 699us/step - loss: 2.8606e-04 - mse: 2.8606e-04 - mae: 0.0108 - val_loss: 2.6482e-04 - val_mse: 2.6482e-04 - val_mae: 0.0109\n",
      "Epoch 10/150\n",
      "1027/1027 [==============================] - 1s 693us/step - loss: 2.7999e-04 - mse: 2.7999e-04 - mae: 0.0107 - val_loss: 2.5097e-04 - val_mse: 2.5097e-04 - val_mae: 0.0104\n",
      "Epoch 11/150\n",
      "1027/1027 [==============================] - 1s 682us/step - loss: 2.7170e-04 - mse: 2.7170e-04 - mae: 0.0105 - val_loss: 2.5101e-04 - val_mse: 2.5101e-04 - val_mae: 0.0104\n",
      "Epoch 12/150\n",
      "1027/1027 [==============================] - 1s 691us/step - loss: 2.6250e-04 - mse: 2.6250e-04 - mae: 0.0103 - val_loss: 2.4067e-04 - val_mse: 2.4067e-04 - val_mae: 0.0101\n",
      "Epoch 13/150\n",
      "1027/1027 [==============================] - 1s 697us/step - loss: 2.5624e-04 - mse: 2.5624e-04 - mae: 0.0102 - val_loss: 3.0489e-04 - val_mse: 3.0489e-04 - val_mae: 0.0120\n",
      "Epoch 14/150\n",
      "1027/1027 [==============================] - 1s 686us/step - loss: 2.5692e-04 - mse: 2.5692e-04 - mae: 0.0101 - val_loss: 2.3659e-04 - val_mse: 2.3659e-04 - val_mae: 0.0100\n",
      "Epoch 15/150\n",
      "1027/1027 [==============================] - 1s 700us/step - loss: 2.4971e-04 - mse: 2.4971e-04 - mae: 0.0100 - val_loss: 2.4211e-04 - val_mse: 2.4211e-04 - val_mae: 0.0099\n",
      "Epoch 16/150\n",
      "1027/1027 [==============================] - 1s 710us/step - loss: 2.4215e-04 - mse: 2.4215e-04 - mae: 0.0099 - val_loss: 2.4889e-04 - val_mse: 2.4889e-04 - val_mae: 0.0099\n",
      "Epoch 17/150\n",
      "1027/1027 [==============================] - 1s 685us/step - loss: 2.3909e-04 - mse: 2.3909e-04 - mae: 0.0098 - val_loss: 2.3943e-04 - val_mse: 2.3943e-04 - val_mae: 0.0105\n",
      "Epoch 18/150\n",
      "1027/1027 [==============================] - 1s 688us/step - loss: 2.3470e-04 - mse: 2.3470e-04 - mae: 0.0097 - val_loss: 2.5180e-04 - val_mse: 2.5180e-04 - val_mae: 0.0100\n",
      "Epoch 19/150\n",
      "1027/1027 [==============================] - 1s 689us/step - loss: 2.4172e-04 - mse: 2.4172e-04 - mae: 0.0098 - val_loss: 2.2762e-04 - val_mse: 2.2762e-04 - val_mae: 0.0095\n",
      "Epoch 20/150\n",
      "1027/1027 [==============================] - 1s 695us/step - loss: 2.3181e-04 - mse: 2.3181e-04 - mae: 0.0096 - val_loss: 2.5263e-04 - val_mse: 2.5263e-04 - val_mae: 0.0107\n",
      "Epoch 21/150\n",
      "1027/1027 [==============================] - 1s 701us/step - loss: 2.2694e-04 - mse: 2.2694e-04 - mae: 0.0095 - val_loss: 2.2667e-04 - val_mse: 2.2667e-04 - val_mae: 0.0096\n",
      "Epoch 22/150\n",
      "1027/1027 [==============================] - 1s 688us/step - loss: 2.2613e-04 - mse: 2.2613e-04 - mae: 0.0095 - val_loss: 2.1815e-04 - val_mse: 2.1815e-04 - val_mae: 0.0097\n",
      "Epoch 23/150\n",
      "1027/1027 [==============================] - 1s 691us/step - loss: 2.2853e-04 - mse: 2.2853e-04 - mae: 0.0095 - val_loss: 2.2526e-04 - val_mse: 2.2526e-04 - val_mae: 0.0098\n",
      "Epoch 24/150\n",
      "1027/1027 [==============================] - 1s 694us/step - loss: 2.2294e-04 - mse: 2.2294e-04 - mae: 0.0094 - val_loss: 2.6728e-04 - val_mse: 2.6728e-04 - val_mae: 0.0113\n",
      "Epoch 25/150\n",
      "1027/1027 [==============================] - 1s 694us/step - loss: 2.2186e-04 - mse: 2.2186e-04 - mae: 0.0094 - val_loss: 2.3646e-04 - val_mse: 2.3646e-04 - val_mae: 0.0100\n",
      "Epoch 26/150\n",
      "1027/1027 [==============================] - 1s 689us/step - loss: 2.2228e-04 - mse: 2.2228e-04 - mae: 0.0094 - val_loss: 2.1772e-04 - val_mse: 2.1772e-04 - val_mae: 0.0097\n",
      "Epoch 27/150\n",
      "1027/1027 [==============================] - 1s 749us/step - loss: 2.1842e-04 - mse: 2.1842e-04 - mae: 0.0093 - val_loss: 2.3169e-04 - val_mse: 2.3169e-04 - val_mae: 0.0097\n",
      "Epoch 28/150\n",
      "1027/1027 [==============================] - 1s 701us/step - loss: 2.1871e-04 - mse: 2.1871e-04 - mae: 0.0093 - val_loss: 2.4255e-04 - val_mse: 2.4255e-04 - val_mae: 0.0098\n",
      "Epoch 29/150\n",
      "1027/1027 [==============================] - 1s 748us/step - loss: 2.1768e-04 - mse: 2.1768e-04 - mae: 0.0093 - val_loss: 2.4321e-04 - val_mse: 2.4321e-04 - val_mae: 0.0108\n",
      "Epoch 30/150\n",
      "1027/1027 [==============================] - 1s 689us/step - loss: 2.1429e-04 - mse: 2.1429e-04 - mae: 0.0092 - val_loss: 2.1628e-04 - val_mse: 2.1628e-04 - val_mae: 0.0095\n",
      "Epoch 31/150\n",
      "1027/1027 [==============================] - 1s 700us/step - loss: 2.1496e-04 - mse: 2.1496e-04 - mae: 0.0092 - val_loss: 2.0261e-04 - val_mse: 2.0261e-04 - val_mae: 0.0092\n",
      "Epoch 32/150\n",
      "1027/1027 [==============================] - 1s 691us/step - loss: 2.1285e-04 - mse: 2.1285e-04 - mae: 0.0092 - val_loss: 2.2335e-04 - val_mse: 2.2335e-04 - val_mae: 0.0097\n",
      "Epoch 33/150\n",
      "1027/1027 [==============================] - 1s 690us/step - loss: 2.1397e-04 - mse: 2.1397e-04 - mae: 0.0091 - val_loss: 2.1072e-04 - val_mse: 2.1072e-04 - val_mae: 0.0093\n",
      "Epoch 34/150\n",
      "1027/1027 [==============================] - 1s 690us/step - loss: 2.0925e-04 - mse: 2.0925e-04 - mae: 0.0091 - val_loss: 2.1195e-04 - val_mse: 2.1195e-04 - val_mae: 0.0093\n",
      "Epoch 35/150\n",
      "1027/1027 [==============================] - 1s 707us/step - loss: 2.0783e-04 - mse: 2.0783e-04 - mae: 0.0090 - val_loss: 2.0605e-04 - val_mse: 2.0605e-04 - val_mae: 0.0092\n",
      "Epoch 36/150\n",
      "1027/1027 [==============================] - 1s 696us/step - loss: 2.0982e-04 - mse: 2.0982e-04 - mae: 0.0091 - val_loss: 2.2479e-04 - val_mse: 2.2479e-04 - val_mae: 0.0094\n",
      "Epoch 37/150\n",
      "1027/1027 [==============================] - 1s 732us/step - loss: 2.0548e-04 - mse: 2.0548e-04 - mae: 0.0090 - val_loss: 2.0758e-04 - val_mse: 2.0758e-04 - val_mae: 0.0093\n",
      "Epoch 38/150\n",
      "1027/1027 [==============================] - 1s 701us/step - loss: 2.0525e-04 - mse: 2.0525e-04 - mae: 0.0090 - val_loss: 2.0827e-04 - val_mse: 2.0827e-04 - val_mae: 0.0092\n",
      "Epoch 39/150\n",
      "1027/1027 [==============================] - 1s 711us/step - loss: 2.0357e-04 - mse: 2.0357e-04 - mae: 0.0090 - val_loss: 2.1091e-04 - val_mse: 2.1091e-04 - val_mae: 0.0096\n",
      "Epoch 40/150\n",
      "1027/1027 [==============================] - 1s 703us/step - loss: 2.0487e-04 - mse: 2.0487e-04 - mae: 0.0090 - val_loss: 2.2677e-04 - val_mse: 2.2677e-04 - val_mae: 0.0098\n",
      "Epoch 41/150\n",
      "1027/1027 [==============================] - 1s 747us/step - loss: 2.0394e-04 - mse: 2.0394e-04 - mae: 0.0090 - val_loss: 2.4511e-04 - val_mse: 2.4511e-04 - val_mae: 0.0103\n",
      "Epoch 42/150\n",
      "1027/1027 [==============================] - 1s 730us/step - loss: 2.0572e-04 - mse: 2.0572e-04 - mae: 0.0090 - val_loss: 2.1862e-04 - val_mse: 2.1862e-04 - val_mae: 0.0093\n",
      "Epoch 43/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1027/1027 [==============================] - ETA: 0s - loss: 2.0392e-04 - mse: 2.0392e-04 - mae: 0.009 - 1s 675us/step - loss: 2.0303e-04 - mse: 2.0303e-04 - mae: 0.0090 - val_loss: 2.1199e-04 - val_mse: 2.1199e-04 - val_mae: 0.0096\n",
      "Epoch 44/150\n",
      "1027/1027 [==============================] - 1s 667us/step - loss: 2.0139e-04 - mse: 2.0139e-04 - mae: 0.0089 - val_loss: 2.0795e-04 - val_mse: 2.0795e-04 - val_mae: 0.0091\n",
      "Epoch 45/150\n",
      "1027/1027 [==============================] - 1s 665us/step - loss: 2.0014e-04 - mse: 2.0014e-04 - mae: 0.0089 - val_loss: 2.1479e-04 - val_mse: 2.1479e-04 - val_mae: 0.0092\n",
      "Epoch 46/150\n",
      "1027/1027 [==============================] - 1s 675us/step - loss: 2.0083e-04 - mse: 2.0083e-04 - mae: 0.0089 - val_loss: 2.0326e-04 - val_mse: 2.0326e-04 - val_mae: 0.0092\n",
      "Epoch 47/150\n",
      "1027/1027 [==============================] - 1s 671us/step - loss: 2.0035e-04 - mse: 2.0035e-04 - mae: 0.0089 - val_loss: 2.0628e-04 - val_mse: 2.0628e-04 - val_mae: 0.0092\n",
      "Epoch 48/150\n",
      "1027/1027 [==============================] - 1s 686us/step - loss: 1.9845e-04 - mse: 1.9845e-04 - mae: 0.0088 - val_loss: 2.0115e-04 - val_mse: 2.0115e-04 - val_mae: 0.0092\n",
      "Epoch 49/150\n",
      "1027/1027 [==============================] - 1s 673us/step - loss: 1.9601e-04 - mse: 1.9601e-04 - mae: 0.0087 - val_loss: 2.1077e-04 - val_mse: 2.1077e-04 - val_mae: 0.0091\n",
      "Epoch 50/150\n",
      "1027/1027 [==============================] - 1s 667us/step - loss: 1.9639e-04 - mse: 1.9639e-04 - mae: 0.0088 - val_loss: 1.9792e-04 - val_mse: 1.9792e-04 - val_mae: 0.0090\n",
      "Epoch 51/150\n",
      "1027/1027 [==============================] - 1s 671us/step - loss: 1.9489e-04 - mse: 1.9489e-04 - mae: 0.0088 - val_loss: 2.0398e-04 - val_mse: 2.0398e-04 - val_mae: 0.0091\n",
      "Epoch 52/150\n",
      "1027/1027 [==============================] - 1s 676us/step - loss: 1.9796e-04 - mse: 1.9796e-04 - mae: 0.0088 - val_loss: 2.0808e-04 - val_mse: 2.0808e-04 - val_mae: 0.0091\n",
      "Epoch 53/150\n",
      "1027/1027 [==============================] - 1s 665us/step - loss: 1.9791e-04 - mse: 1.9791e-04 - mae: 0.0088 - val_loss: 1.9913e-04 - val_mse: 1.9913e-04 - val_mae: 0.0090\n",
      "Epoch 54/150\n",
      "1027/1027 [==============================] - 1s 683us/step - loss: 1.9339e-04 - mse: 1.9339e-04 - mae: 0.0087 - val_loss: 1.9383e-04 - val_mse: 1.9383e-04 - val_mae: 0.0088\n",
      "Epoch 55/150\n",
      "1027/1027 [==============================] - 1s 683us/step - loss: 1.9640e-04 - mse: 1.9640e-04 - mae: 0.0088 - val_loss: 2.0690e-04 - val_mse: 2.0690e-04 - val_mae: 0.0093\n",
      "Epoch 56/150\n",
      "1027/1027 [==============================] - 1s 684us/step - loss: 1.9099e-04 - mse: 1.9099e-04 - mae: 0.0087 - val_loss: 2.3648e-04 - val_mse: 2.3648e-04 - val_mae: 0.0102\n",
      "Epoch 57/150\n",
      "1027/1027 [==============================] - 1s 688us/step - loss: 1.9261e-04 - mse: 1.9261e-04 - mae: 0.0087 - val_loss: 2.0162e-04 - val_mse: 2.0162e-04 - val_mae: 0.0093\n",
      "Epoch 58/150\n",
      "1027/1027 [==============================] - 1s 691us/step - loss: 1.9392e-04 - mse: 1.9392e-04 - mae: 0.0087 - val_loss: 1.9952e-04 - val_mse: 1.9952e-04 - val_mae: 0.0091\n",
      "Epoch 59/150\n",
      "1027/1027 [==============================] - 1s 679us/step - loss: 1.9286e-04 - mse: 1.9286e-04 - mae: 0.0087 - val_loss: 2.1498e-04 - val_mse: 2.1498e-04 - val_mae: 0.0096\n",
      "Epoch 60/150\n",
      "1027/1027 [==============================] - 1s 670us/step - loss: 1.9215e-04 - mse: 1.9215e-04 - mae: 0.0087 - val_loss: 1.9818e-04 - val_mse: 1.9818e-04 - val_mae: 0.0091\n",
      "Epoch 61/150\n",
      "1027/1027 [==============================] - 1s 683us/step - loss: 1.8983e-04 - mse: 1.8983e-04 - mae: 0.0086 - val_loss: 2.0531e-04 - val_mse: 2.0531e-04 - val_mae: 0.0091\n",
      "Epoch 62/150\n",
      "1027/1027 [==============================] - 1s 687us/step - loss: 1.9047e-04 - mse: 1.9047e-04 - mae: 0.0087 - val_loss: 2.0678e-04 - val_mse: 2.0678e-04 - val_mae: 0.0092\n",
      "Epoch 63/150\n",
      "1027/1027 [==============================] - 1s 678us/step - loss: 1.8863e-04 - mse: 1.8863e-04 - mae: 0.0086 - val_loss: 1.9760e-04 - val_mse: 1.9760e-04 - val_mae: 0.0091\n",
      "Epoch 64/150\n",
      "1027/1027 [==============================] - 1s 668us/step - loss: 1.8902e-04 - mse: 1.8902e-04 - mae: 0.0086 - val_loss: 1.9504e-04 - val_mse: 1.9504e-04 - val_mae: 0.0092\n",
      "Epoch 65/150\n",
      "1027/1027 [==============================] - 1s 671us/step - loss: 1.8914e-04 - mse: 1.8914e-04 - mae: 0.0086 - val_loss: 1.9292e-04 - val_mse: 1.9292e-04 - val_mae: 0.0089\n",
      "Epoch 66/150\n",
      "1027/1027 [==============================] - 1s 681us/step - loss: 1.8770e-04 - mse: 1.8770e-04 - mae: 0.0086 - val_loss: 2.0744e-04 - val_mse: 2.0744e-04 - val_mae: 0.0094\n",
      "Epoch 67/150\n",
      "1027/1027 [==============================] - 1s 684us/step - loss: 1.8847e-04 - mse: 1.8847e-04 - mae: 0.0086 - val_loss: 1.9983e-04 - val_mse: 1.9983e-04 - val_mae: 0.0094\n",
      "Epoch 68/150\n",
      "1027/1027 [==============================] - 1s 676us/step - loss: 1.8819e-04 - mse: 1.8819e-04 - mae: 0.0086 - val_loss: 2.0002e-04 - val_mse: 2.0002e-04 - val_mae: 0.0091\n",
      "Epoch 69/150\n",
      "1027/1027 [==============================] - 1s 680us/step - loss: 1.8622e-04 - mse: 1.8622e-04 - mae: 0.0085 - val_loss: 2.1344e-04 - val_mse: 2.1344e-04 - val_mae: 0.0093\n",
      "Epoch 70/150\n",
      "1027/1027 [==============================] - 1s 677us/step - loss: 1.8934e-04 - mse: 1.8934e-04 - mae: 0.0086 - val_loss: 1.9596e-04 - val_mse: 1.9596e-04 - val_mae: 0.0089\n",
      "Epoch 71/150\n",
      "1027/1027 [==============================] - 1s 694us/step - loss: 1.8452e-04 - mse: 1.8452e-04 - mae: 0.0085 - val_loss: 1.9403e-04 - val_mse: 1.9403e-04 - val_mae: 0.0088\n",
      "Epoch 72/150\n",
      "1027/1027 [==============================] - 1s 682us/step - loss: 1.8638e-04 - mse: 1.8638e-04 - mae: 0.0085 - val_loss: 2.0852e-04 - val_mse: 2.0852e-04 - val_mae: 0.0096\n",
      "Epoch 73/150\n",
      "1027/1027 [==============================] - 1s 679us/step - loss: 1.8999e-04 - mse: 1.8999e-04 - mae: 0.0086 - val_loss: 1.9748e-04 - val_mse: 1.9748e-04 - val_mae: 0.0089\n",
      "Epoch 74/150\n",
      "1027/1027 [==============================] - 1s 682us/step - loss: 1.8763e-04 - mse: 1.8763e-04 - mae: 0.0086 - val_loss: 1.9679e-04 - val_mse: 1.9679e-04 - val_mae: 0.0092\n",
      "Epoch 75/150\n",
      "1027/1027 [==============================] - 1s 679us/step - loss: 1.8603e-04 - mse: 1.8603e-04 - mae: 0.0086 - val_loss: 1.9496e-04 - val_mse: 1.9496e-04 - val_mae: 0.0090\n",
      "Epoch 76/150\n",
      "1027/1027 [==============================] - 1s 686us/step - loss: 1.8566e-04 - mse: 1.8566e-04 - mae: 0.0085 - val_loss: 1.8875e-04 - val_mse: 1.8875e-04 - val_mae: 0.0087\n",
      "Epoch 77/150\n",
      "1027/1027 [==============================] - 1s 681us/step - loss: 1.8310e-04 - mse: 1.8310e-04 - mae: 0.0085 - val_loss: 2.0714e-04 - val_mse: 2.0714e-04 - val_mae: 0.0091\n",
      "Epoch 78/150\n",
      "1027/1027 [==============================] - 1s 689us/step - loss: 1.8286e-04 - mse: 1.8286e-04 - mae: 0.0085 - val_loss: 1.9257e-04 - val_mse: 1.9257e-04 - val_mae: 0.0088\n",
      "Epoch 79/150\n",
      "1027/1027 [==============================] - 1s 687us/step - loss: 1.8186e-04 - mse: 1.8186e-04 - mae: 0.0085 - val_loss: 1.9395e-04 - val_mse: 1.9395e-04 - val_mae: 0.0088\n",
      "Epoch 80/150\n",
      "1027/1027 [==============================] - 1s 677us/step - loss: 1.8698e-04 - mse: 1.8698e-04 - mae: 0.0086 - val_loss: 1.9746e-04 - val_mse: 1.9746e-04 - val_mae: 0.0090\n",
      "Epoch 81/150\n",
      "1027/1027 [==============================] - 1s 692us/step - loss: 1.8185e-04 - mse: 1.8185e-04 - mae: 0.0085 - val_loss: 1.8790e-04 - val_mse: 1.8790e-04 - val_mae: 0.0088\n",
      "Epoch 82/150\n",
      "1027/1027 [==============================] - 1s 703us/step - loss: 1.8204e-04 - mse: 1.8204e-04 - mae: 0.0085 - val_loss: 1.9402e-04 - val_mse: 1.9402e-04 - val_mae: 0.0089\n",
      "Epoch 83/150\n",
      "1027/1027 [==============================] - 1s 698us/step - loss: 1.8416e-04 - mse: 1.8416e-04 - mae: 0.0085 - val_loss: 2.1850e-04 - val_mse: 2.1850e-04 - val_mae: 0.0101\n",
      "Epoch 84/150\n",
      "1027/1027 [==============================] - 1s 696us/step - loss: 1.8267e-04 - mse: 1.8267e-04 - mae: 0.0085 - val_loss: 2.1481e-04 - val_mse: 2.1481e-04 - val_mae: 0.0095\n",
      "Epoch 85/150\n",
      "1027/1027 [==============================] - 1s 693us/step - loss: 1.8737e-04 - mse: 1.8737e-04 - mae: 0.0085 - val_loss: 1.9853e-04 - val_mse: 1.9853e-04 - val_mae: 0.0089\n",
      "Epoch 86/150\n",
      "1027/1027 [==============================] - 1s 692us/step - loss: 1.7926e-04 - mse: 1.7926e-04 - mae: 0.0084 - val_loss: 2.2833e-04 - val_mse: 2.2833e-04 - val_mae: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/150\n",
      "1027/1027 [==============================] - 1s 668us/step - loss: 1.8502e-04 - mse: 1.8502e-04 - mae: 0.0085 - val_loss: 1.9362e-04 - val_mse: 1.9362e-04 - val_mae: 0.0088\n",
      "Epoch 88/150\n",
      "1027/1027 [==============================] - 1s 670us/step - loss: 1.7929e-04 - mse: 1.7929e-04 - mae: 0.0084 - val_loss: 1.9194e-04 - val_mse: 1.9194e-04 - val_mae: 0.0090\n",
      "Epoch 89/150\n",
      "1027/1027 [==============================] - 1s 672us/step - loss: 1.7987e-04 - mse: 1.7987e-04 - mae: 0.0085 - val_loss: 1.9494e-04 - val_mse: 1.9494e-04 - val_mae: 0.0088\n",
      "Epoch 90/150\n",
      "1027/1027 [==============================] - 1s 676us/step - loss: 1.8073e-04 - mse: 1.8073e-04 - mae: 0.0084 - val_loss: 2.0018e-04 - val_mse: 2.0018e-04 - val_mae: 0.0090\n",
      "Epoch 91/150\n",
      "1027/1027 [==============================] - 1s 675us/step - loss: 1.7800e-04 - mse: 1.7800e-04 - mae: 0.0084 - val_loss: 1.9848e-04 - val_mse: 1.9848e-04 - val_mae: 0.0089\n",
      "Epoch 92/150\n",
      "1027/1027 [==============================] - 1s 668us/step - loss: 1.7988e-04 - mse: 1.7988e-04 - mae: 0.0084 - val_loss: 1.9509e-04 - val_mse: 1.9509e-04 - val_mae: 0.0089\n",
      "Epoch 93/150\n",
      "1027/1027 [==============================] - 1s 676us/step - loss: 1.8217e-04 - mse: 1.8217e-04 - mae: 0.0084 - val_loss: 1.8723e-04 - val_mse: 1.8723e-04 - val_mae: 0.0088\n",
      "Epoch 94/150\n",
      "1027/1027 [==============================] - 1s 673us/step - loss: 1.7782e-04 - mse: 1.7782e-04 - mae: 0.0084 - val_loss: 1.9172e-04 - val_mse: 1.9172e-04 - val_mae: 0.0090\n",
      "Epoch 95/150\n",
      "1027/1027 [==============================] - 1s 667us/step - loss: 1.7891e-04 - mse: 1.7891e-04 - mae: 0.0084 - val_loss: 2.3304e-04 - val_mse: 2.3304e-04 - val_mae: 0.0098\n",
      "Epoch 96/150\n",
      "1027/1027 [==============================] - 1s 673us/step - loss: 1.7986e-04 - mse: 1.7986e-04 - mae: 0.0084 - val_loss: 1.9142e-04 - val_mse: 1.9142e-04 - val_mae: 0.0090\n",
      "Epoch 97/150\n",
      "1027/1027 [==============================] - 1s 672us/step - loss: 1.7560e-04 - mse: 1.7560e-04 - mae: 0.0083 - val_loss: 1.8706e-04 - val_mse: 1.8706e-04 - val_mae: 0.0087\n",
      "Epoch 98/150\n",
      "1027/1027 [==============================] - 1s 674us/step - loss: 1.7756e-04 - mse: 1.7756e-04 - mae: 0.0084 - val_loss: 2.1253e-04 - val_mse: 2.1253e-04 - val_mae: 0.0093\n",
      "Epoch 99/150\n",
      "1027/1027 [==============================] - 1s 678us/step - loss: 1.8013e-04 - mse: 1.8013e-04 - mae: 0.0084 - val_loss: 1.8587e-04 - val_mse: 1.8587e-04 - val_mae: 0.0086\n",
      "Epoch 100/150\n",
      "1027/1027 [==============================] - 1s 680us/step - loss: 1.7746e-04 - mse: 1.7746e-04 - mae: 0.0083 - val_loss: 1.9265e-04 - val_mse: 1.9265e-04 - val_mae: 0.0089\n",
      "Epoch 101/150\n",
      "1027/1027 [==============================] - 1s 688us/step - loss: 1.7642e-04 - mse: 1.7642e-04 - mae: 0.0084 - val_loss: 1.8946e-04 - val_mse: 1.8946e-04 - val_mae: 0.0090\n",
      "Epoch 102/150\n",
      "1027/1027 [==============================] - 1s 676us/step - loss: 1.7676e-04 - mse: 1.7676e-04 - mae: 0.0084 - val_loss: 1.9243e-04 - val_mse: 1.9243e-04 - val_mae: 0.0089\n",
      "Epoch 103/150\n",
      "1027/1027 [==============================] - 1s 684us/step - loss: 1.7714e-04 - mse: 1.7714e-04 - mae: 0.0083 - val_loss: 2.0241e-04 - val_mse: 2.0241e-04 - val_mae: 0.0091\n",
      "Epoch 104/150\n",
      "1027/1027 [==============================] - 1s 677us/step - loss: 1.7730e-04 - mse: 1.7730e-04 - mae: 0.0083 - val_loss: 2.2222e-04 - val_mse: 2.2222e-04 - val_mae: 0.0099\n",
      "Epoch 105/150\n",
      "1027/1027 [==============================] - 1s 687us/step - loss: 1.7656e-04 - mse: 1.7656e-04 - mae: 0.0084 - val_loss: 1.9868e-04 - val_mse: 1.9868e-04 - val_mae: 0.0093\n",
      "Epoch 106/150\n",
      "1027/1027 [==============================] - 1s 677us/step - loss: 1.7930e-04 - mse: 1.7930e-04 - mae: 0.0083 - val_loss: 1.9276e-04 - val_mse: 1.9276e-04 - val_mae: 0.0088\n",
      "Epoch 107/150\n",
      "1027/1027 [==============================] - 1s 678us/step - loss: 1.7472e-04 - mse: 1.7472e-04 - mae: 0.0083 - val_loss: 1.8882e-04 - val_mse: 1.8882e-04 - val_mae: 0.0087\n",
      "Epoch 108/150\n",
      "1027/1027 [==============================] - 1s 683us/step - loss: 1.7566e-04 - mse: 1.7566e-04 - mae: 0.0083 - val_loss: 1.9416e-04 - val_mse: 1.9416e-04 - val_mae: 0.0090\n",
      "Epoch 109/150\n",
      "1027/1027 [==============================] - 1s 685us/step - loss: 1.7796e-04 - mse: 1.7796e-04 - mae: 0.0084 - val_loss: 1.9051e-04 - val_mse: 1.9051e-04 - val_mae: 0.0088\n",
      "Epoch 110/150\n",
      "1027/1027 [==============================] - 1s 682us/step - loss: 1.7585e-04 - mse: 1.7585e-04 - mae: 0.0083 - val_loss: 1.9022e-04 - val_mse: 1.9022e-04 - val_mae: 0.0090\n",
      "Epoch 111/150\n",
      "1027/1027 [==============================] - 1s 696us/step - loss: 1.7340e-04 - mse: 1.7340e-04 - mae: 0.0083 - val_loss: 1.9017e-04 - val_mse: 1.9017e-04 - val_mae: 0.0087\n",
      "Epoch 112/150\n",
      "1027/1027 [==============================] - 1s 713us/step - loss: 1.7579e-04 - mse: 1.7579e-04 - mae: 0.0083 - val_loss: 1.9243e-04 - val_mse: 1.9243e-04 - val_mae: 0.0087\n",
      "Epoch 113/150\n",
      "1027/1027 [==============================] - 1s 695us/step - loss: 1.7123e-04 - mse: 1.7123e-04 - mae: 0.0082 - val_loss: 2.2344e-04 - val_mse: 2.2344e-04 - val_mae: 0.0102\n",
      "Epoch 114/150\n",
      "1027/1027 [==============================] - 1s 724us/step - loss: 1.7661e-04 - mse: 1.7661e-04 - mae: 0.0083 - val_loss: 1.9046e-04 - val_mse: 1.9046e-04 - val_mae: 0.0088\n",
      "Epoch 115/150\n",
      "1027/1027 [==============================] - 1s 698us/step - loss: 1.7785e-04 - mse: 1.7785e-04 - mae: 0.0083 - val_loss: 1.8818e-04 - val_mse: 1.8818e-04 - val_mae: 0.0087\n",
      "Epoch 116/150\n",
      "1027/1027 [==============================] - 1s 712us/step - loss: 1.7345e-04 - mse: 1.7345e-04 - mae: 0.0083 - val_loss: 1.8901e-04 - val_mse: 1.8901e-04 - val_mae: 0.0088\n",
      "Epoch 117/150\n",
      "1027/1027 [==============================] - 1s 707us/step - loss: 1.7313e-04 - mse: 1.7313e-04 - mae: 0.0083 - val_loss: 1.9488e-04 - val_mse: 1.9488e-04 - val_mae: 0.0088\n",
      "Epoch 118/150\n",
      "1027/1027 [==============================] - 1s 706us/step - loss: 1.7468e-04 - mse: 1.7468e-04 - mae: 0.0083 - val_loss: 1.8762e-04 - val_mse: 1.8762e-04 - val_mae: 0.0087\n",
      "Epoch 119/150\n",
      "1027/1027 [==============================] - 1s 722us/step - loss: 1.7027e-04 - mse: 1.7027e-04 - mae: 0.0082 - val_loss: 1.9102e-04 - val_mse: 1.9102e-04 - val_mae: 0.0088\n",
      "Epoch 120/150\n",
      "1027/1027 [==============================] - 1s 702us/step - loss: 1.7143e-04 - mse: 1.7143e-04 - mae: 0.0082 - val_loss: 1.9337e-04 - val_mse: 1.9337e-04 - val_mae: 0.0088\n",
      "Epoch 121/150\n",
      "1027/1027 [==============================] - 1s 690us/step - loss: 1.7570e-04 - mse: 1.7570e-04 - mae: 0.0083 - val_loss: 1.9672e-04 - val_mse: 1.9672e-04 - val_mae: 0.0088\n",
      "Epoch 122/150\n",
      " 941/1027 [==========================>...] - ETA: 0s - loss: 1.7364e-04 - mse: 1.7364e-04 - mae: 0.0083"
     ]
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "history=NNmodel.fit(X_train_scaled, y_train_scaled, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.to_csv('x.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User entered data\n",
    "make='Audi'\n",
    "model='A1'\n",
    "year=2017\n",
    "transmission='Manual'\n",
    "mileage=15000\n",
    "fuelType='Petrol'\n",
    "tax=150\n",
    "mpg=55\n",
    "engineSize=1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an array with the user entered data\n",
    "def new_data(make,model,year,transmission,mileage,fuelType,tax,mpg,engineSize):\n",
    "    new_data=[]\n",
    "     \n",
    "    new_data.append(year)\n",
    "    new_data.append(mileage)\n",
    "    new_data.append(tax)\n",
    "    new_data.append(mpg)\n",
    "    new_data.append(engineSize)\n",
    "    \n",
    "    model_array=find_model_array(model)\n",
    "    for i in model_array:\n",
    "        new_data.append(i)\n",
    "        \n",
    "    trans_array=find_trans_array(transmission)\n",
    "    for i in trans_array:\n",
    "        new_data.append(i)\n",
    "    \n",
    "    fuelType_array=find_fuelType_array(fuelType)\n",
    "    for i in fuelType_array:\n",
    "        new_data.append(i)\n",
    "    \n",
    "    make_array=find_make_array(make)\n",
    "    for i in make_array:\n",
    "        new_data.append(i)\n",
    "    \n",
    "    return new_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model_array(model):\n",
    "    model_matrix=pd.read_csv('Matrix/Make_Model_Matrix.csv')\n",
    "    model_matrix=model_matrix.fillna(0)\n",
    "    find_model=model_matrix.loc[model_matrix['model']==model,:]\n",
    "    model_array=find_model.iloc[0,2:].tolist()\n",
    "    return (model_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trans_array(transmission):\n",
    "    trans_matrix=pd.read_csv('Matrix/Transmission_Matrix.csv')\n",
    "    find_trans=trans_matrix.loc[trans_matrix['transmission']==transmission,:]\n",
    "    trans_array=find_trans.iloc[0,1:].tolist()\n",
    "    return (trans_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fuelType_array(fuelType):\n",
    "    fuelType_matrix=pd.read_csv('Matrix/fuelType_Matrix.csv')\n",
    "    fuelType_matrix=fuelType_matrix.fillna(0)\n",
    "    find_fuelType=fuelType_matrix.loc[fuelType_matrix['fuelType']==fuelType,:]\n",
    "    fuelType_array=find_fuelType.iloc[0,1:].tolist()\n",
    "    return (fuelType_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_make_array(make):\n",
    "    make_matrix=pd.read_csv('Matrix/Make_Matrix.csv')\n",
    "    make_matrix=make_matrix.fillna(0)\n",
    "    find_make=make_matrix.loc[make_matrix['make']==make,:]\n",
    "    make_array=find_make.iloc[0,1:].tolist()\n",
    "    return (make_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_list=new_data(make,model,year,transmission,mileage,fuelType,tax,mpg,engineSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Price from User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array(new_data_list).reshape(1,195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new= X_scaler.transform(X_new)\n",
    "y_new= NNmodel.predict(X_new)\n",
    "#invert normalize\n",
    "y_new = y_scaler.inverse_transform(y_new) \n",
    "X_new = X_scaler.inverse_transform(X_new)\n",
    "print(\"X=%s, Predicted=%s\" % (X_new[0], y_new[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
